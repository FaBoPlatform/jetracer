{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 評価用動画の作成 (Race24), 決勝\n",
    "\n",
    "3_annotationで変換した３つの走行モデルと, 20_detect の環境認識モデルをつかって評価用の動画を作成します。<br>\n",
    "ミニカーバトル  2024年"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets\n",
    "from ipywidgets import Button, Layout, Textarea, HBox, VBox, Label\n",
    "import os\n",
    "import glob\n",
    "import datetime\n",
    "\n",
    "l = Layout(flex='0 1 auto', height='100px', min_height='100px', width='auto')\n",
    "process_widget = ipywidgets.Textarea(description='ログ', value='', layout=l)\n",
    "\n",
    "process_no = 0\n",
    "def write_log(msg):\n",
    "    global process_widget, process_no\n",
    "    process_no = process_no + 1\n",
    "    process_widget.value = str(process_no) + \": \" + msg + \"\\n\" + process_widget.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOAD_TASK = ['camera']\n",
    "CATEGORIES = [\"start\",\"road\", \"right\", \"left\", \"parking\", \"etc\"]\n",
    "\n",
    "BASE_FPS = [30,60]\n",
    "\n",
    "IMG_WIDTH = 224\n",
    "IMG_HEIGHT = 224\n",
    "current_path = os.getcwd()\n",
    "SKIP = [1,2,3,4,5]\n",
    "\n",
    "model_a_widget = ipywidgets.Dropdown(options=[],description='走行モデル')\n",
    "model_a_time_widget = ipywidgets.Label(description='作成日時')\n",
    "load_a_button = ipywidgets.Button(description='走行モデル読込み')\n",
    "model_b_widget = ipywidgets.Dropdown(options=[],description='走行モデル')\n",
    "model_b_time_widget = ipywidgets.Label(description='作成日時')\n",
    "load_b_button = ipywidgets.Button(description='走行モデルを読込み')\n",
    "model_e_widget = ipywidgets.Dropdown(options=[],description='環境モデル')\n",
    "model_e_time_widget = ipywidgets.Label(description='作成日時')\n",
    "load_e_button = ipywidgets.Button(description='環境モデル読込み')\n",
    "\n",
    "load_datasets_widget0 = ipywidgets.Dropdown(options=[], description='dataset0')\n",
    "load_task_widget0 = ipywidgets.Dropdown(options=LOAD_TASK, description='task')\n",
    "load_datasets_widget1 = ipywidgets.Dropdown(options=[], description='dataset1')\n",
    "load_task_widget1 = ipywidgets.Dropdown(options=LOAD_TASK, description='task')\n",
    "\n",
    "camera_fps_widget = ipywidgets.Dropdown(options=BASE_FPS, description='camera_fps')\n",
    "\n",
    "movie_button = ipywidgets.Button(description='動画の作成')\n",
    "movie_name_widget = ipywidgets.Text(description='動画名',value=\"run_video_dual_merge_trt\")\n",
    "movie_skip_dropdown = ipywidgets.Dropdown(options=SKIP, description='skip(枚)', index=1)\n",
    "\n",
    "building_dropbox = ipywidgets.Dropdown(options=CATEGORIES, description='Building')\n",
    "speed_raw_fast_slider = ipywidgets.IntSlider(description='Speed fast', min=1, max=224, step=1, value=224, orientation='horizontal')\n",
    "speed_raw_slow_slider = ipywidgets.IntSlider(description='Speed slow', min=1, max=224, step=1, value=120, orientation='horizontal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_load_task(change):\n",
    "    global current_path\n",
    "    try:\n",
    "        path = os.path.join(current_path,load_task_widget0.value)\n",
    "        files = os.listdir(path)\n",
    "        dirs = [f for f in files if os.path.isdir(os.path.join(path, f))]\n",
    "        dirs = [f for f in files if f != \".ipynb_checkpoints\"]\n",
    "        dirs = sorted(dirs)\n",
    "        load_datasets_widget0.options = dirs\n",
    "        load_datasets_widget1.options = dirs\n",
    "    except:\n",
    "        write_log(path + \"が存在していません。\")\n",
    "        load_datasets_widget0.options = []\n",
    "        load_datasets_widget1.options = []\n",
    "load_task_widget0.observe(change_load_task)\n",
    "change_load_task(LOAD_TASK[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from packaging import version\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "def load_model(widget, model_var_name):\n",
    "    write_log(f\"load_model{widget.value}\")\n",
    "    #global device\n",
    "    torchvision_version = version.parse(torchvision.__version__)\n",
    "    if model_var_name == \"model_e_trt\":\n",
    "        output_dim = len(CATEGORIES)\n",
    "    else:\n",
    "        output_dim = 4\n",
    "        \n",
    "    # デバイスの選択\n",
    "    if torch.backends.mps.is_available():\n",
    "        device = torch.device('mps')\n",
    "    elif torch.cuda.is_available():\n",
    "        device = torch.device('cuda')\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "    write_log(f\"{widget.value}の読込を実行します(初回は時間がかかります)。\")\n",
    "    if torchvision_version >= version.parse(\"0.13\"):\n",
    "        from torchvision.models.resnet import ResNet18_Weights, resnet18\n",
    "        model = resnet18(weights=None)\n",
    "        model.fc = torch.nn.Linear(model.fc.in_features, output_dim)\n",
    "        model.load_state_dict(torch.load(widget.value, map_location=device))\n",
    "        model.eval()\n",
    "    else:\n",
    "        model = torchvision.models.resnet18(pretrained=False)\n",
    "        model.fc = torch.nn.Linear(512, output_dim)\n",
    "        model.load_state_dict(torch.load(widget.value))\n",
    "        model.eval()\n",
    "\n",
    "    model = model.to(device)\n",
    "    globals()[model_var_name] = model  # 成功した場合、グローバル変数にモデルをセット\n",
    "    load_flag_var_name = f\"load_{model_var_name}\"\n",
    "    write_log(f\"{load_flag_var_name}の読込に成功しました。\")\n",
    "    globals()[load_flag_var_name] = True  # 対応するloadフラグをTrueにセット\n",
    "\n",
    "    #get_jetson_nano_memory_usage()\n",
    "   \n",
    "# モデル読み込み関数を各ボタンのクリックイベントにバインドする例\n",
    "load_a_button.on_click(lambda change: load_model(model_a_widget, 'model_a_trt'))\n",
    "load_b_button.on_click(lambda change: load_model(model_b_widget, 'model_b_trt'))\n",
    "load_e_button.on_click(lambda change: load_model(model_e_widget, 'model_e_trt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_list(type):\n",
    "    try:\n",
    "        files = glob.glob(type + '/*.pth', recursive=True)\n",
    "        ts = os.path.getctime(files[0])\n",
    "        d = datetime.datetime.fromtimestamp(ts)\n",
    "        s = d.strftime('%Y-%m-%d %H:%M:%S')\n",
    "        if type == \"model\":\n",
    "            model_a_widget.options = files\n",
    "            model_a_time_widget.value = s\n",
    "            model_b_widget.options = files\n",
    "            model_b_time_widget.value = s\n",
    "        elif type == \"model_c\":\n",
    "            model_e_widget.options = files\n",
    "            model_e_time_widget.value = s\n",
    "    except Exception as e:\n",
    "        model_a_widget.options = []\n",
    "        model_b_widget.options = []\n",
    "        model_e_widget.options = []\n",
    "        write_log(f\"Error:{e}\")\n",
    "model_list(\"model\")\n",
    "model_list(\"model_c\")\n",
    "\n",
    "def update_model_time_widget(widget, time_widget):\n",
    "    \"\"\"指定されたウィジェットのファイル選択が変更された際の処理。ファイルの作成時間を表示ウィジェットに設定する。\"\"\"\n",
    "    file = widget.value\n",
    "    try:\n",
    "        ts = os.path.getctime(file)\n",
    "        d = datetime.datetime.fromtimestamp(ts)\n",
    "        s = d.strftime('%Y-%m-%d %H:%M:%S')\n",
    "        time_widget.value = s\n",
    "    except Exception as e:\n",
    "        time_widget.value = \"Error: \" + str(e)\n",
    "\n",
    "# 各モデル選択ウィジェットの変更を監視し、対応する時刻表示ウィジェットを更新\n",
    "model_a_widget.observe(lambda change: update_model_time_widget(model_a_widget, model_a_time_widget), names='value')\n",
    "model_b_widget.observe(lambda change: update_model_time_widget(model_b_widget, model_b_time_widget), names='value')\n",
    "model_e_widget.observe(lambda change: update_model_time_widget(model_e_widget, model_e_time_widget), names='value')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ロジック\n",
    "\n",
    "31_dual_camera_runからコピーしてもってくる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(target):\n",
    "    if target == \"right\": \n",
    "        name = \"model_right\"\n",
    "        return name,model_a_trt\n",
    "    elif target == \"left\":\n",
    "        name = \"model_left\"\n",
    "        return name,model_b_trt\n",
    "    else:\n",
    "        name = \"model_left\"\n",
    "        return name,model_b_trt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_color = \"\"\n",
    "def change_color(color):\n",
    "    global selected_color\n",
    "    write_log(f\"Change color:{color}\")\n",
    "    selected_color = color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_params():\n",
    "    time_count = 0\n",
    "    time_count_stop = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_count = 0\n",
    "\n",
    "def check_non_detection_period(elapsed_time_ms):\n",
    "    global time_count\n",
    "    time_count+=1\n",
    "    emulation_time = ((1000/camera_fps_widget.value) * movie_skip_dropdown.value) * time_count\n",
    "    #write_log(f\"emulation_time:{emulation_time}\")\n",
    "    if emulation_time > elapsed_time_ms:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def update_last_detect_time():\n",
    "    global time_count\n",
    "    time_count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stop_time(target):\n",
    "    if target == \"library\" or target == \"market\":\n",
    "        return 1000\n",
    "    else:\n",
    "        return 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_count_stop = 0\n",
    "def check_stop_time(current_time, target_detected_time, stop_time):\n",
    "    global time_count_stop\n",
    "    time_count_stop += 1\n",
    "    emulation_time = (1000/camera_fps_widget.value) * movie_skip_dropdown.value * time_count_stop\n",
    "    \n",
    "    if emulation_time > stop_time:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    #if current_time - target_detected_time >= stop_time:\n",
    "    #    return True:\n",
    "    #else:\n",
    "    #    return False:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_status_and_action(current_status, category_index, last_detect, detect_count, prebuilding, target, stop_time, target_detected_time=None):\n",
    "    \"\"\"\n",
    "    現在の状態に基づき、次のアクションを決定し、状態を更新します。ターゲット発見後、指定された秒数でSTOPに遷移します。\n",
    "\n",
    "    Args:\n",
    "        current_status (int): 現在の状態\n",
    "        category_index (int): 現在の認識結果のカテゴリインデックス\n",
    "        last_detect (int): 前回の認識結果のカテゴリインデックス\n",
    "        detect_count (int): 連続して認識された回数\n",
    "        prebuilding (str): ターゲットの1つ前の建物名\n",
    "        target (str): ターゲットとなる建物名\n",
    "        stop_time (int): ターゲットを検出してから停止するまでの秒数\n",
    "        target_detected_time (float, optional): ターゲットを最初に検出した時刻\n",
    "\n",
    "    Returns:\n",
    "        tuple: 更新された状態、連続認識回数、ターゲット検出時刻\n",
    "    \"\"\"\n",
    "    global selected_model\n",
    "    new_status = current_status\n",
    "    new_detect_count = detect_count\n",
    "    current_time = time.time()  # 現在時刻を取得\n",
    "\n",
    "    # STATUS_TARGETに遷移した直後にタイムスタンプを記録\n",
    "    if current_status == STATUS_TARGET and target_detected_time is None:\n",
    "        target_detected_time = current_time\n",
    "\n",
    "    # STATUS_TARGET状態で、指定された秒数が経過した場合にSTATUS_STOPに遷移\n",
    "    if current_status == STATUS_TARGET:\n",
    "        if check_stop_time(current_time, target_detected_time, stop_time):\n",
    "            change_color(\"red\")\n",
    "            new_status = STATUS_STOP\n",
    "            #PCA9685.set_channel_value(THROTTLE_CH, pwm_stop)    \n",
    "            target_detected_time = None  # タイムスタンプをリセット\n",
    "            write_log(\"STOP!\")\n",
    "            \n",
    "\n",
    "    if current_status == STATUS_OUT_A:\n",
    "        if CATEGORIES[category_index] == target:\n",
    "            if CATEGORIES[last_detect] == target:\n",
    "                new_detect_count += 1\n",
    "                if new_detect_count > 10:\n",
    "                    write_log(f\"Detect1 {target}\")\n",
    "                    change_color(\"yellow\")\n",
    "                    new_status = STATUS_OUT_B\n",
    "                    new_detect_count = 0\n",
    "                    update_last_detect_time()\n",
    "            else:\n",
    "                new_detect_count = 1\n",
    "    elif current_status == STATUS_OUT_B:\n",
    "        if check_non_detection_period(3000) == True:\n",
    "            if CATEGORIES[category_index] == prebuilding:\n",
    "                if CATEGORIES[last_detect] == prebuilding:\n",
    "                    new_detect_count += 1\n",
    "                    if new_detect_count > 5:\n",
    "                        write_log(f\"Detect2 {prebuilding}\")\n",
    "                        change_color(\"purple\")\n",
    "                        new_status = STATUS_IN\n",
    "                        new_detect_count = 0\n",
    "                else:\n",
    "                    new_detect_count = 1\n",
    "    elif current_status == STATUS_IN:\n",
    "        if CATEGORIES[category_index] == target:\n",
    "            if CATEGORIES[last_detect] == target:\n",
    "                new_detect_count += 1\n",
    "                if new_detect_count > 5:\n",
    "                    change_color(\"orange\")\n",
    "                    write_log(f\"Detect3 {target}\")\n",
    "                    new_status = STATUS_TARGET\n",
    "                    new_detect_count = 0\n",
    "            else:\n",
    "                new_detect_count = 1\n",
    "    return new_status, new_detect_count, target_detected_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 選択された色によって異なる色の円を描く\n",
    "def draw_led(img0, selected_color):\n",
    "    if selected_color == \"white\":\n",
    "        color = (255, 255, 255) # BGRで白\n",
    "    elif selected_color == \"yellow\":\n",
    "        color = (0, 255, 255) # BGRで黄\n",
    "    elif selected_color == \"orange\":\n",
    "        # オレンジ色の正確なBGR値については調整が必要かもしれません\n",
    "        color = (0, 165, 255) # BGRでオレンジ\n",
    "    elif selected_color == \"red\":\n",
    "        color = (0, 0, 255) # BGRで赤\n",
    "    elif selected_color == \"purple\":\n",
    "        color = (255, 0, 255) # BGRで紫\n",
    "    else:\n",
    "        color = (0, 0, 0) # その他の場合は黒\n",
    "\n",
    "    # 3つの円を描く\n",
    "    for i in range(3):\n",
    "        img0 = cv2.circle(img0, (95 + i*15, 30), 5, color, -1) # -1で中を塗りつぶす\n",
    "\n",
    "    return img0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import glob\n",
    "from utils import preprocess\n",
    "import re\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import subprocess\n",
    "import time\n",
    "import datetime\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def extract_numbers(filename):\n",
    "    matches = re.findall(r'(\\d+)', filename)\n",
    "    if matches and len(matches) >= 3: \n",
    "        return int(matches[-1])  \n",
    "    else:\n",
    "        return float('inf')\n",
    "\n",
    "def get_file_names(path):\n",
    "    file_names = os.listdir(path)\n",
    "    file_names = [os.path.join(path, file_name) for file_name in file_names]\n",
    "    image_names = []\n",
    "\n",
    "    image_names = sorted(file_names, key=lambda f: extract_numbers(os.path.basename(f)))\n",
    "    image_names = [f for f in image_names if os.path.splitext(f)[1].lower() == \".jpg\"]\n",
    "    \n",
    "    return image_names\n",
    "    \n",
    "def make_movie(change):\n",
    "    global model_a_trt,model_b_trt,model_c_trt,model_e_trt,current_path, status, count\n",
    "\n",
    "    if not movie_name_widget.value.strip():\n",
    "        write_log(\"ファイル名を指定してください。\")\n",
    "        return \n",
    "    \n",
    "    init_params()\n",
    "    \n",
    "    change_color(\"white\")\n",
    "    count = 0\n",
    "    path = os.path.join(current_path, \"video\")\n",
    "    if not os.path.exists(path):\n",
    "        if os.name == 'nt':\n",
    "            # Windowsの場合\n",
    "            os.makedirs(path, exist_ok=True)\n",
    "        else:\n",
    "            # Mac/Linuxの場合\n",
    "            subprocess.call(['mkdir', '-p', path])\n",
    "    output = path + \"/\" + movie_name_widget.value + \".mp4\"\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    fps = int(camera_fps_widget.value/movie_skip_dropdown.value)\n",
    "    outfh = cv2.VideoWriter(output, fourcc, fps, (224*2, 224))\n",
    "    xy_path0 = os.path.join(current_path, load_task_widget0.value, load_datasets_widget0.value, \"xy\")     \n",
    "    file_list0 = get_file_names(xy_path0)\n",
    "    xy_path1 = os.path.join(current_path, load_task_widget1.value, load_datasets_widget1.value, \"xy\")     \n",
    "    file_list1 = get_file_names(xy_path1)\n",
    "    detect_count = 0\n",
    "    last_detect = -1\n",
    "    lap = 0\n",
    "    model = model_a_trt\n",
    "    target = building_dropbox.value\n",
    "    stop_time = get_stop_time(target)\n",
    "    target_detected_time = None\n",
    "    try:\n",
    "        res_num = len(file_list0)\n",
    "        write_log(f\"画像枚数:{res_num}\")\n",
    "        count = 0\n",
    "        skip_movie = movie_skip_dropdown.value\n",
    "        last_lap_time = -5\n",
    "        current_time = 0\n",
    "        terminal_time = 1/(int(30/skip_movie))\n",
    "        process_drive_time = 0\n",
    "        process_detect_time = 0\n",
    "        total_process_drive_time = 0\n",
    "        total_process_detect_time = 0\n",
    "        target_detect_time = 0\n",
    "        stop_time = get_stop_time(target)\n",
    "        for i, file_name in enumerate(file_list0):\n",
    "            if i % skip_movie == 0:\n",
    "                current_time += terminal_time\n",
    "                img0 = cv2.imread(file_name)\n",
    "                img1 = cv2.imread(file_list1[i])\n",
    "                process_detect_time = time.time()\n",
    "                # 画像の前処理\n",
    "                img0_preprocessed = preprocess(img0)\n",
    "                img1_preprocessed = preprocess(img1)\n",
    "                process_drive_time = time.time()\n",
    "                output = model(img0_preprocessed).detach().cpu().numpy().flatten()\n",
    "                result_x = float(output[0])\n",
    "                result_y = float(output[1])\n",
    "                result_x = int(IMG_WIDTH * (result_x / 2.0 + 0.5))\n",
    "                result_y = int(IMG_HEIGHT * (result_y / 2.0 + 0.5))    \n",
    "                img0 = cv2.circle(img0, (int(result_x), int(result_y)), 8, (255, 0, 0), 3)\n",
    "                \n",
    "                # Speed\n",
    "                result_speed = output[3]\n",
    "                result_speed = int(IMG_WIDTH * (result_speed / 2.0 + 0.5))\n",
    "                if result_speed > 224:\n",
    "                    result_speed = 244\n",
    "                elif result_speed < 0:\n",
    "                    result_speed = 0\n",
    "                total_process_drive_time += time.time() - process_drive_time \n",
    "                 \n",
    "                output = model_e_trt(img1_preprocessed).detach()\n",
    "                output = F.softmax(output, dim=1).cpu().numpy().flatten()\n",
    "                category_index = output.argmax()\n",
    "                total_process_detect_time += time.time() - process_detect_time \n",
    "                \n",
    "                # ターゲットの1つ前の建物名を取得\n",
    "                #prebuilding = get_target(building_dropbox.value)\n",
    "                # 環境認識後の処理（動画作成時も同じロジックを使う)\n",
    "                #status, detect_count, target_detected_time = update_status_and_action(status, category_index, last_detect, detect_count, prebuilding, target, stop_time, target_detected_time)\n",
    "                last_detect = category_index\n",
    "            \n",
    "                model_name, model = get_model(CATEGORIES[category_index])                \n",
    "                # 使用可能なモデル名\n",
    "                str_models = [\"model_left\", \"model_right\"]\n",
    "                # モデル名を画像に表示\n",
    "                status_pos_y = 20  # 初期のY位置\n",
    "                status_pos_x = 80  # 初期のx位置\n",
    "                for str_model in str_models:\n",
    "                    # 選択されているモデルは赤色、それ以外は白色で表示\n",
    "                    if str_model == model_name:\n",
    "                        color = (0, 0, 255)  # BGRで赤\n",
    "                    else:\n",
    "                        color = (255, 255, 255)  # BGRで白\n",
    "\n",
    "                    # モデル名を画像に描画\n",
    "                    img0 = cv2.putText(img0, str_model, (status_pos_x, status_pos_y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "                    status_pos_y += 20  # 次のモデル名のために位置を下に移動\n",
    "                    \n",
    "                img0 = cv2.line(img0,(6,0),(6,224),(0,0,0),5)\n",
    "                img0 = cv2.line(img0,(7,224-result_speed),(7,224),(255,0,0),3)\n",
    "                img0 = cv2.putText(img0,\"speed:\"+str(result_speed),(160,215),cv2.FONT_HERSHEY_SIMPLEX,0.3,(255,255,255))\n",
    "\n",
    "                # LED\n",
    "                #img0 = draw_led(img0, selected_color)\n",
    "                    \n",
    "                # 各カテゴリのスコアをパーセンテージで表示する改善版\n",
    "                thickness = 2  # テキストの太さを細くする\n",
    "                font_scale = 0.4  # フォントの大きさを小さく調整\n",
    "                font_height = 15  # フォントの高さ（およその値）\n",
    "\n",
    "                # 画像の高さを取得\n",
    "                img_height = img1.shape[0]\n",
    "\n",
    "                # 表示可能な最大カテゴリ数を計算\n",
    "                max_categories = (img_height // font_height) - 2  # 上下に少し余裕を持たせる\n",
    "\n",
    "                # 各カテゴリのスコアをパーセンテージで表示（表示可能数に制限）\n",
    "                for h, score in enumerate(list(output)[:max_categories]):\n",
    "                    text = f\"{CATEGORIES[h]} : {score * 100:.1f}%\"  # 小数点以下1桁まで表示\n",
    "                    color = (0, 0, 255) if h == category_index else (255, 255, 255)  # 最も高いスコアのカテゴリを赤色で表示\n",
    "                    position = (10, h * font_height + 20)  # テキストを描画する位置\n",
    "                    img1 = cv2.putText(img1, text, position, cv2.FONT_HERSHEY_SIMPLEX, font_scale, color, thickness)\n",
    "\n",
    "                if len(CATEGORIES) > max_categories:\n",
    "                    # 画像に収まりきらないカテゴリがある場合の処理\n",
    "                    overflow_text = f\"...and more\"\n",
    "                    img1 = cv2.putText(img1, overflow_text, (10, (max_categories + 1) * font_height + 20), cv2.FONT_HERSHEY_SIMPLEX, font_scale, (255, 255, 255), thickness)\n",
    "\n",
    "                if i%(skip_movie*10) == 0:\n",
    "                    write_log(f\"{current_time:.1f}秒まで完了, 走行推論: {total_process_drive_time/10*1000:.1f}ms, 環境推論: {total_process_detect_time/10*1000:.1f}ms, {int(i/skip_movie)}枚目/{int(res_num/skip_movie)}枚中を処理中\")\n",
    "                    total_process_detect_time = 0\n",
    "                    total_process_drive_time = 0\n",
    "                \n",
    "                img = cv2.hconcat([img0, img1])  # imgは224x448サイズになります\n",
    "        \n",
    "                outfh.write(img)\n",
    "                del img\n",
    "    except Exception as e:\n",
    "        write_log(f\"Error: {e}\")\n",
    "    finally:\n",
    "        # エラーが発生しても確実にリソースを解放する\n",
    "        outfh.release()\n",
    "        write_log(\"動画の出力が完了しました。\")\n",
    "\n",
    "movie_button.on_click(make_movie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7ed75a21e954cc3881aa26adc2789a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<hr style=\"border-color:gray;margin:10px 0\"/>'), HTML(value='<b>【1.走行モデル(右側)の選択】</b…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "separator = ipywidgets.HTML('<hr style=\"border-color:gray;margin:10px 0\"/>')\n",
    "title1 = ipywidgets.HTML('<b>【1.走行モデル(右側)の選択】</b> 走行モデルを選択してください。')\n",
    "title2 = ipywidgets.HTML('<b>【2.走行モデル(左側)の選択】</b> 走行モデルを選択してください。')\n",
    "title5 = ipywidgets.HTML('<b>【5.環境モデルの選択】</b> 環境モデルを選択してください。')\n",
    "title6 = ipywidgets.HTML('<b>【6.目標】</b> 目標物を選択してください。')\n",
    "title7 = ipywidgets.HTML('<b>【7.データセットの選択】</b> データセットを選択してください。')\n",
    "title8 = ipywidgets.HTML('<b>【8.走行動画の作成】</b> 動画ファイル名を指定してください。')\n",
    "\n",
    "convert_widget = ipywidgets.VBox([\n",
    "    separator,\n",
    "    title1,\n",
    "    ipywidgets.HBox([model_a_widget,model_a_time_widget,load_a_button]),\n",
    "    process_widget,\n",
    "    title2,\n",
    "    ipywidgets.HBox([model_b_widget,model_b_time_widget,load_b_button]),\n",
    "    process_widget,\n",
    "    title5,\n",
    "    ipywidgets.HBox([model_e_widget,model_e_time_widget,load_e_button]),\n",
    "    process_widget,\n",
    "    title6,\n",
    "    building_dropbox,\n",
    "    speed_raw_fast_slider,\n",
    "    speed_raw_slow_slider,\n",
    "    title7,\n",
    "    ipywidgets.HBox([load_datasets_widget0,load_task_widget0]),\n",
    "    ipywidgets.HBox([load_datasets_widget1,load_task_widget1]),\n",
    "    process_widget,\n",
    "    title8,\n",
    "    camera_fps_widget,\n",
    "    ipywidgets.HBox([movie_name_widget,movie_skip_dropdown,movie_button]),\n",
    "    process_widget,\n",
    "])\n",
    "display(convert_widget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
