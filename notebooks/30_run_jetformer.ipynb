{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 走行\n",
    "\n",
    "このNotebookで自動走行をおこないます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jetsonの認識"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Jetson.GPIO as GPIO\n",
    "\n",
    "BOARD_NAME=GPIO.gpio_pin_data.get_data()[0]\n",
    "if BOARD_NAME == \"JETSON_NX\":\n",
    "    print(\"Jetson Xavier NXを認識\")\n",
    "    I2C_BUSNUM = 8\n",
    "    MODE = 2\n",
    "elif BOARD_NAME == \"JETSON_XAVIER\":\n",
    "    print(\"Jetson AGX Xavierを認識\")\n",
    "    I2C_BUSNUM = 8\n",
    "    MODE = 2\n",
    "elif BOARD_NAME == \"JETSON_NANO\":\n",
    "    print(\"Jetson NANOを認識\")\n",
    "    I2C_BUSNUM = 1\n",
    "    MODE = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Orin Nanoは7を使用\n",
    "I2C_BUSNUM = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo \"jetson\" | sudo -S nvpmodel -m $MODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo \"jetson\" | sudo -S nvpmodel -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo \"jetson\" | sudo -S jetson_clocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ログの表示用 Widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets\n",
    "from ipywidgets import Button, Layout, Textarea, HBox, VBox, Label\n",
    "import os\n",
    "import glob\n",
    "\n",
    "l = Layout(flex='0 1 auto', height='100px', min_height='100px', width='auto')\n",
    "process_widget = ipywidgets.Textarea(description='ログ', value='', layout=l)\n",
    "\n",
    "process_no = 0\n",
    "def write_log(msg):\n",
    "    global process_widget, process_no\n",
    "    process_no = process_no + 1\n",
    "    process_widget.value = str(process_no) + \": \" + msg + \"\\n\" + process_widget.value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PWMの値の読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Fabo_PCA9685\n",
    "import time\n",
    "import pkg_resources\n",
    "import smbus\n",
    "import time\n",
    "import json\n",
    "\n",
    "SMBUS='smbus'\n",
    "BUSNUM=I2C_BUSNUM\n",
    "SERVO_HZ=60\n",
    "INITIAL_VALUE=300\n",
    "bus = smbus.SMBus(BUSNUM)\n",
    "PCA9685 = Fabo_PCA9685.PCA9685(bus,INITIAL_VALUE,address=0x40)\n",
    "PCA9685.set_hz(SERVO_HZ)\n",
    "\n",
    "STEERING_CH = 0\n",
    "THROTTLE_CH = 1\n",
    "direction = 0\n",
    "\n",
    "pwm_front = 0\n",
    "pwm_back = 0\n",
    "\n",
    "with open('pwm_params.json') as f:\n",
    "    json_str = json.load(f)\n",
    "    \n",
    "    pwm_stop = json_str[\"pwm_speed\"][\"stop\"]\n",
    "    pwm_front = json_str[\"pwm_speed\"][\"front\"]\n",
    "    pwm_back = json_str[\"pwm_speed\"][\"back\"]\n",
    "    pwm_left = json_str[\"pwm_steering\"][\"left\"]\n",
    "    pwm_center = json_str[\"pwm_steering\"][\"center\"]\n",
    "    pwm_right = json_str[\"pwm_steering\"][\"right\"]\n",
    "\n",
    "    \n",
    "if pwm_front >= pwm_back:\n",
    "    direction = 0\n",
    "else:\n",
    "    direction = 1\n",
    "    \n",
    "PCA9685.set_channel_value(STEERING_CH, pwm_center)\n",
    "PCA9685.set_channel_value(THROTTLE_CH, pwm_stop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## カメラの読込\n",
    "\n",
    "この部分でエラーが発生する場合は、Jetsonの再起動をお願いします。<br>\n",
    "それでも、カメラが認識できない場合は、ケーブルの接続確認をしてください。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jetcam.csi_camera import CSICamera\n",
    "\n",
    "camera = CSICamera(width=224, height=224, capture_fps=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 走行処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision.models import resnet18\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "import math\n",
    "\n",
    "IMG_WIDTH=224\n",
    "IMG_HEIGHT=224\n",
    "\n",
    "# この部分は、画像から情報を取り出すためのものです。名前が「抽出器」であるように、これは画像から重要な特徴を見つけ出すために使います。\n",
    "class ImageFeatureExtractor(nn.Module):\n",
    "    \"\"\"Image Feature Extractor using ResNet18\"\"\"\n",
    "    def __init__(self, output_size, dropout=0.1):\n",
    "        super().__init__()\n",
    "        # ResNet18は事前に訓練された大きなネットワークで、画像から特徴を抽出するのにとても役立ちます。\n",
    "        self.resnet = resnet18(pretrained=True)\n",
    "        # ここではネットワークの最後に新しい部分を追加しています。これは特徴を取り出すためのものです。\n",
    "        self.resnet.fc = nn.Sequential(\n",
    "          nn.Linear(self.resnet.fc.in_features, output_size),\n",
    "          nn.ReLU(inplace=True),\n",
    "          nn.Dropout(dropout),\n",
    "        )\n",
    "\n",
    "    # この部分は、画像を取り、それを特徴抽出器に通すことで特徴を取り出します。\n",
    "    def forward(self, x):\n",
    "        return self.resnet(x)\n",
    "\n",
    "# この部分は、情報を処理するためのものです。これは「Transformer」部分と呼ばれ、順序を考慮しながら情報を分析します。\n",
    "class TransformerBlock(nn.Module):\n",
    "    \"\"\"Transformer Block for processing sequence data.\"\"\"\n",
    "    def __init__(self, input_size, nhead, nhid, nlayers, dropout=0.1):\n",
    "        super().__init__()\n",
    "        # 位置エンコーディングは、順序を覚えるための特別な技術です。\n",
    "        self.pos_encoder = PositionalEncoding(input_size, dropout)\n",
    "        # この部分は実際の「Transformer」です。これが情報を処理します。\n",
    "        encoder_layers = TransformerEncoderLayer(input_size, nhead, nhid, dropout)\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n",
    "\n",
    "    # この部分は、情報を「Transformer」に通すことで情報を処理します。\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)\n",
    "        x = self.pos_encoder(x)\n",
    "        return self.transformer_encoder(x)\n",
    "\n",
    "# この部分は、上記のすべてを組み合わせて全体のモデルを形成します。画像から特徴を取り出し、それを「Transformer」に通すことで情報を処理します。\n",
    "class JetFormerModel(nn.Module):\n",
    "    \"\"\"Main model that combines ImageFeatureExtractor and TransformerBlock.\"\"\"\n",
    "    def __init__(self, ninp, nhead, nhid, nlayers, dropout=0.1):\n",
    "        super(JetFormerModel, self).__init__()\n",
    "        # 画像から特徴を抽出する部分\n",
    "        self.img_feature_extractor = ImageFeatureExtractor(ninp//2, dropout)\n",
    "        # 以前のハンドルのペアを処理する部分\n",
    "        self.previous_handle_fc = nn.Sequential(\n",
    "            nn.Linear(2, ninp//2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "        # 「Transformer」部分\n",
    "        self.transformer_block = TransformerBlock(ninp, nhead, nhid, nlayers, dropout)\n",
    "        # 最後に、結果を得るための部分\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(ninp, 64),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(64, 2),\n",
    "        )\n",
    "\n",
    "    # この部分は、すべての部品を一緒に組み立てて結果を得る部分です。\n",
    "    def forward(self, images, previous_handle_pairs):\n",
    "        img_features = self.img_feature_extractor(images)\n",
    "        previous_handle_features = self.previous_handle_fc(previous_handle_pairs)\n",
    "        out = torch.cat([img_features, previous_handle_features], dim=-1)\n",
    "        out = self.transformer_block(out)\n",
    "        out = self.fc(out[:, 0, :])\n",
    "        return out\n",
    "\n",
    "# 位置エンコーディングは、情報がどの順序で来たかを覚えるためのものです。\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "      x = x + self.pe[:x.size(0), :]\n",
    "      return self.dropout(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 必要なライブラリやツールを読み込みます\n",
    "import os\n",
    "import cv2\n",
    "import datetime\n",
    "import os\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import cv2\n",
    "import PIL.Image\n",
    "import numpy as np\n",
    "\n",
    "batch_size = 128\n",
    "num_epochs = 500\n",
    "nhid = 1024\n",
    "ninp = 512\n",
    "nhead = 4\n",
    "nlayers = 4\n",
    "learning_rate = 0.00006\n",
    "# 「ディープラーニング」のためのモデル（計算の設計図）を読み込みます\n",
    "# 「ディープラーニング」はコンピュータに大量のデータから学習させる技術の一つです\n",
    "device = torch.device('cuda')\n",
    "model = JetFormerModel(ninp=ninp, nhead=nhead, nhid=nhid, nlayers=nlayers).to(device)\n",
    "\n",
    "# 学習した結果（重みやバイアス）を読み込みます\n",
    "# 「重み」や「バイアス」はモデルの中の計算に使われるパラメータ（数値）で、これらの値によりモデルの出力結果が変わります\n",
    "checkpoint = torch.load('./model_checkpoint_0801_170.pth')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()  # モデルを評価モードに切り替えます\n",
    "load = True\n",
    "# 画像の色の強さを調整するための値を定義します\n",
    "mean = torch.Tensor([0.485, 0.456, 0.406]).cuda()\n",
    "std = torch.Tensor([0.229, 0.224, 0.225]).cuda()\n",
    "\n",
    "# 画像を処理するための関数を定義します\n",
    "def preprocess(image):\n",
    "    device = torch.device('cuda')\n",
    "    image = PIL.Image.fromarray(image)  # 画像をPIL形式に変換します\n",
    "    image = transforms.functional.to_tensor(image).to(device)  # 画像をテンソル（多次元配列）に変換します\n",
    "    image.sub_(mean[:, None, None]).div_(std[:, None, None])  # 画像の色の強さを調整します\n",
    "    return image[None, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import threading\n",
    "#from utils import preprocess\n",
    "import subprocess\n",
    "import cv2\n",
    "import time\n",
    "#from torch2trt import TRTModule\n",
    "import subprocess\n",
    "import datetime\n",
    "\n",
    "\n",
    "model_widget = ipywidgets.Dropdown(options=[],description='モデル')\n",
    "model_time_widget = ipywidgets.Label(description='作成日時')\n",
    "load_button = ipywidgets.Button(description='Load')\n",
    "run_button = ipywidgets.Button(description='Run')\n",
    "stop_button = ipywidgets.Button(description='Stop')\n",
    "pwm_left_widget = ipywidgets.IntText(value=pwm_left,description='PWM 左')\n",
    "pwm_center_widget = ipywidgets.IntText(value=pwm_center,description='PWM 中央')\n",
    "pwm_right_widget = ipywidgets.IntText(value=pwm_right,description='PWM 右')\n",
    "check_left_button = ipywidgets.Button(description='チェック左')\n",
    "check_center_button = ipywidgets.Button(description='チェック中央')\n",
    "check_right_button = ipywidgets.Button(description='チェック右')\n",
    "pwm_stop_widget = ipywidgets.IntText(value=pwm_stop,description='PWM 停止')\n",
    "name_widget = ipywidgets.Text(description='映像の保存先')\n",
    "record_box = ipywidgets.Checkbox(False, description='録画')\n",
    "speed_high_slider = ipywidgets.IntSlider(description='High', min=0, max=100, step=1, value=20, orientation='horizontal')\n",
    "speed_low_slider = ipywidgets.IntSlider(description='Low', min=0, max=100, step=1, value=10, orientation='horizontal')\n",
    "steering_gain_slider = ipywidgets.FloatSlider(description='Steering gain', min=0.1, max=2.0, step=0.1, value=1.0, orientation='horizontal')\n",
    "\n",
    "record = False\n",
    "running = False\n",
    "load = False\n",
    "\n",
    "def map_rc(x, in_min, in_max, out_min, out_max):\n",
    "    return (x - in_min) * (out_max - out_min) // (in_max - in_min) + out_min\n",
    "\n",
    "def handle(x):\n",
    "    global pwm_right,pwm_left,STEERING_CH,PCA9685\n",
    "    x = map_rc(x, 224, 0, pwm_right, pwm_left)\n",
    "    PCA9685.set_channel_value(STEERING_CH, x)\n",
    "    \n",
    "def live():\n",
    "    global device, process, model,running,camera,IMG_WIDTH,record,model_trt,preprocess,pwm_stop,save_dir,num,cv2,count,speed_high_slider,speed_low_slider,steering_gain_slider\n",
    "    \n",
    "    count = 1\n",
    "    num = 1\n",
    "    xy_sequence = torch.tensor([[(112/IMG_WIDTH - 0.5) * 2, (112/IMG_HEIGHT - 0.5) * 2]], device=device).float()  # 初期の位置を決めます\n",
    "\n",
    "    while running:\n",
    "        image = camera.read()\n",
    "        if record == True:\n",
    "            remarked_img = image.copy()\n",
    "            \n",
    "        preprocessed = preprocess(image)  # 画像を処理します\n",
    "        preprocessed = preprocessed.to(device)  # 画像をGPUに送ります\n",
    "        output = model(preprocessed, xy_sequence)  # モデルに画像を入力して結果をもらいます\n",
    "        \n",
    "        output = output.detach().cpu().numpy().flatten()  # 結果を使いやすい形に変換します\n",
    "        xy_sequence = torch.tensor([output], device=device).float()  # 次の画像で使うために、結果を保存します\n",
    "\n",
    "        result_x = output[0]  # 結果からx座標（左右の位置）を取り出します\n",
    "        result_speed = output[1]  # 結果から速度を取り出します\n",
    "        \n",
    "        x = int(IMG_WIDTH * (result_x / 2.0 + 0.5))\n",
    "        #y = int(IMG_WIDTH * (y / 2.0 + 0.5))\n",
    "        speed = int(IMG_WIDTH * (result_speed / 2.0 + 0.5))\n",
    "        handle(x)\n",
    "        \n",
    "        if direction == 0:\n",
    "            pwm_speed_high = pwm_stop + speed_high_slider.value\n",
    "            pwm_speed_low = pwm_stop + speed_low_slider.value\n",
    "        else:\n",
    "            pwm_speed_high = pwm_stop - speed_high_slider.value\n",
    "            pwm_speed_low = pwm_stop - speed_low_slider.value\n",
    "        #PCA9685.set_channel_value(THROTTLE_CH, pwm_speed)\n",
    "        \n",
    "        if speed > 112:\n",
    "            PCA9685.set_channel_value(THROTTLE_CH, pwm_speed_high)\n",
    "        elif speed <= 112:\n",
    "            PCA9685.set_channel_value(THROTTLE_CH, pwm_speed_low)\n",
    "\n",
    "        if record == True:\n",
    "            if num % 2 == 0:\n",
    "                name = \"0_0_{:0=5}.jpg\".format(num)\n",
    "                image_path = os.path.join(save_dir, name)\n",
    "                cv2.imwrite(image_path, remarked_img)\n",
    "            num += 1\n",
    "        count += 1\n",
    "        \n",
    "        #write_log(\"Count:\" + str(count))\n",
    "        \n",
    "def run(change):\n",
    "    global running,execute_thread,name_widget,save_dir,start_time,load,speed_high_slider,speed_low_slider,steering_gain_slider\n",
    "    \n",
    "    if load == False:\n",
    "        write_log(\"モデルが読み込まれていません\")\n",
    "        return\n",
    "\n",
    "    if running == False:\n",
    "        if record == True:\n",
    "            if name_widget.value != \"\":\n",
    "                save_dir = \"run/\" + name_widget.value + \"/xy/\" \n",
    "                if not os.path.exists(save_dir):\n",
    "                    subprocess.call(['mkdir', '-p', save_dir])\n",
    "                write_log(save_dir + \"にデータを保存します。\")            \n",
    "\n",
    "                running = True\n",
    "                execute_thread = threading.Thread(target=live)\n",
    "                execute_thread.start()\n",
    "                start_time = time.time()\n",
    "                write_log(\"AIが起動しました。\")\n",
    "                if direction == 0:\n",
    "                    pwm_speed_high = pwm_stop + speed_high_slider.value\n",
    "                    pwm_speed_low = pwm_stop + speed_low_slider.value\n",
    "                else:\n",
    "                    pwm_speed_high = pwm_stop - speed_high_slider.value\n",
    "                    pwm_speed_low = pwm_stop - speed_low_slider.value\n",
    "                write_log(\"Steering Gain:\" + str(steering_gain_slider.value) + \" Speed High:\" + str(pwm_speed_high) + \" Low:\" + str(pwm_speed_low) + \"で走行開始します。\")\n",
    "            else:\n",
    "                write_log(\"映像の保存先を入力してください。\")\n",
    "        else:\n",
    "            running = True\n",
    "            execute_thread = threading.Thread(target=live)\n",
    "            execute_thread.start()\n",
    "            start_time = time.time()\n",
    "            write_log(\"AIが起動しました。\") \n",
    "            if direction == 0:\n",
    "                pwm_speed_high = pwm_stop + speed_high_slider.value\n",
    "                pwm_speed_low = pwm_stop + speed_low_slider.value\n",
    "            else:\n",
    "                pwm_speed_high = pwm_stop - speed_high_slider.value\n",
    "                pwm_speed_low = pwm_stop - speed_low_slider.value\n",
    "            write_log(\"Steering Gain:\" + str(steering_gain_slider.value) + \" Speed High:\" + str(pwm_speed_high) + \" Low:\" + str(pwm_speed_low) + \"で走行開始します。\")\n",
    "        \n",
    "    \n",
    "def stop(change):\n",
    "    global running,execute_thread,end_time,start_time,count,pwm_stop\n",
    "    if running == True:\n",
    "        PCA9685.set_channel_value(THROTTLE_CH, pwm_stop)\n",
    "        try:\n",
    "            end_time = time.time() - start_time\n",
    "            fps = count/int(end_time)\n",
    "            process_time = int((end_time/count)*1000)\n",
    "        except:\n",
    "            fps = -1\n",
    "            process_time = -1\n",
    "        \n",
    "        write_log(\"AIを停止しました。\")\n",
    "        write_log(\"処理結果:FPS: \" + str(round(fps,2)) + \",処理回数: \" + str(count) + \",　処理時間(1回平均値): \" + str(process_time) + \" ms\")\n",
    "        running = False\n",
    "        execute_thread.join()\n",
    "    else:\n",
    "        PCA9685.set_channel_value(THROTTLE_CH, pwm_stop)\n",
    "        write_log(\"現在AIは動いていません。\")\n",
    "\n",
    "def load_model(change):\n",
    "    global model_trt,model_widget,load\n",
    "    try:\n",
    "        #write_log(model_widget.value + \"の読込を実行します(初回は時間がかかります)。\")\n",
    "        #model_trt = TRTModule()\n",
    "        #model_trt.load_state_dict(torch.load(model_widget.value))\n",
    "        #write_log(model_widget.value + \"の読込に成功しました。\")\n",
    "        load = True\n",
    "    except:\n",
    "        write_log(\"[Error]\")\n",
    "        \n",
    "def model_list(change):\n",
    "    global model_widget\n",
    "    try:\n",
    "        files = glob.glob('./model_trt/*.pth', recursive=True)\n",
    "        model_widget.options = files\n",
    "        ts = os.path.getctime(files[0])\n",
    "        d = datetime.datetime.fromtimestamp(ts)\n",
    "        s = d.strftime('%Y-%m-%d %H:%M:%S')\n",
    "        model_time_widget.value = s\n",
    "    except:\n",
    "        model_widget.options = []\n",
    "model_list(\"list\")\n",
    "\n",
    "def change_file(change):\n",
    "    file = model_widget.value\n",
    "    ts = os.path.getctime(file)\n",
    "    d = datetime.datetime.fromtimestamp(ts)\n",
    "    s = d.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    model_time_widget.value = s\n",
    "model_widget.observe(change_file, names='value')\n",
    "\n",
    "def on_video(change):\n",
    "    global record\n",
    "    record^=True\n",
    "    \n",
    "load_button.on_click(load_model)\n",
    "run_button.on_click(run)\n",
    "stop_button.on_click(stop)\n",
    "record_box.observe(on_video)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "走行までの流れは以下の通りです。\n",
    "\n",
    "1. <b>学習済みモデルを指定してLoadする</b><br>\n",
    "2. <b>Steering gainの値を調整する</b><br>\n",
    "初期値は1.0です。0.1〜2.0の値で設定できる、1.0より大きな値にするとハンドルのキレ角が鋭くなる<br>\n",
    "3. <b>High, Lowの値を調整する</b><br>\n",
    "4. <b>[オプション] 走行動画を録画する場合は、録画にチェックマークをいれて、保存ファイル名を指定する</b><br>\n",
    "./runフォルダに保存<br>\n",
    "5. <b>runボタンを押して、プロポの裏側のボタンを押して AIモードで自動走行開始する</b><br>\n",
    "6. <b>終了時は、stopボタンを押す</b><br>\n",
    "録画のチェックマークがついている場合は、stopで録画も終了<br>\n",
    "<br>\n",
    "カメラが60fpsで動いている場合は16ms以内、カメラが30fpsで動いている場合は、33ms以内での処理完了が正常な挙動となります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collection_widget = ipywidgets.VBox([\n",
    "    ipywidgets.HBox([model_widget,model_time_widget,load_button]),\n",
    "    ipywidgets.HBox([steering_gain_slider, speed_high_slider, speed_low_slider]),\n",
    "    ipywidgets.HBox([record_box,name_widget,run_button, stop_button]),\n",
    "    process_widget\n",
    "])\n",
    "display(data_collection_widget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### カメラの終了処理(必須)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "camera.running = False\n",
    "camera.cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
