{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cecea567",
   "metadata": {},
   "source": [
    "# Train\n",
    "\n",
    "データセットを結合して、学習します。\n",
    "\n",
    "Jetson Orin Nanoでは、2000枚のデータセットでも1時間程度で学習はおわります。Jetson Nanoでは、2000枚のデータセットの学習には10時間程度かかります。Jetson Nanoユーザは、300枚を超える学習時は、下記URLから起動できるColabを試してください。\n",
    "\n",
    "https://colab.research.google.com/drive/1GbDrNiosTKSJNOJiCiVgv6V8X-0GDBfW?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa67f88f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "Jetson Orin Nanoを認識: I2Cバス番号: 7, Powerモード: MODE_7W(1)に設定します。\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import Jetson.GPIO as GPIO\n",
    "\n",
    "BOARD_NAME = GPIO.gpio_pin_data.get_data()[0]\n",
    "\n",
    "mode_descriptions = {\n",
    "    \"JETSON_NX\": [\"15W_2CORE\", \"15W_4CORE\", \"15W_6CORE\", \"10W_2CORE\", \"10W_4CORE\"],\n",
    "    \"JETSON_XAVIER\": [\"MAXN\", \"MODE_10W\", \"MODE_15W\", \"MODE_30W\"],\n",
    "    \"JETSON_NANO\": [\"MAXN\", \"5W\"],\n",
    "    \"JETSON_ORIN\": [\"MAXN\", \"MODE_15W\", \"MODE_30W\", \"MODE_40W\"],\n",
    "    \"JETSON_ORIN_NANO\": [\"MODE_15W\", \"MODE_7W\"]\n",
    "}\n",
    "\n",
    "product_names = {\n",
    "    \"JETSON_NX\": \"Jetson Xavier NX\",\n",
    "    \"JETSON_XAVIER\": \"Jetson AGX Xavier\",\n",
    "    \"JETSON_NANO\": \"Jetson Nano\",\n",
    "    \"JETSON_ORIN\": \"Jetson AGX Orin\",\n",
    "    \"JETSON_ORIN_NANO\": \"Jetson Orin Nano\"\n",
    "}\n",
    "\n",
    "# ボードごとのI2Cバス番号と初期Powerモードを定義する\n",
    "board_settings = {\n",
    "    \"JETSON_NX\": (8, 3),\n",
    "    \"JETSON_XAVIER\": (8, 2),\n",
    "    \"JETSON_NANO\": (1, 0),\n",
    "    \"JETSON_ORIN\": (7, 0),\n",
    "    \"JETSON_ORIN_NANO\": (7, 1)\n",
    "}\n",
    "\n",
    "i2c_busnum, power_mode = board_settings.get(BOARD_NAME, (None, None))\n",
    "mode_description = mode_descriptions.get(BOARD_NAME, [])\n",
    "product_name = product_names.get(BOARD_NAME, \"未知のボード\")\n",
    "\n",
    "if power_mode is not None and power_mode < len(mode_description):\n",
    "    mode_str = mode_description[power_mode]\n",
    "    print(\"------------------------------------------------------------\")\n",
    "    print(f\"{product_name}を認識: I2Cバス番号: {i2c_busnum}, Powerモード: {mode_str}({power_mode})に設定します。\")\n",
    "    print(\"------------------------------------------------------------\")\n",
    "else:\n",
    "    print(\"未知のボードまたは不正なモードです。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0eeaffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docker起動のため電力モードは変更できません。\n"
     ]
    }
   ],
   "source": [
    "if (product_name == \"Jetson Orin Nano\") or (product_name == \"Jetson AGX Orin\"):\n",
    "    print(\"Docker起動のため電力モードは変更できません。\")\n",
    "else:\n",
    "    !echo \"jetson\" | sudo -S nvpmodel -m $power_mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f13adbba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVPM WARN: power mode is not set!\n"
     ]
    }
   ],
   "source": [
    "!echo \"jetson\" | sudo -S nvpmodel -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "299da607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docker起動のためjetson_clocksは起動できません。\n"
     ]
    }
   ],
   "source": [
    "if (product_name == \"Jetson Orin Nano\") or (product_name == \"Jetson AGX Orin\"):\n",
    "    print(\"Docker起動のためjetson_clocksは起動できません。\")\n",
    "else:\n",
    "    !echo \"jetson\" | sudo -S jetson_clocks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d5e43a-34f0-47d6-9927-3fbf860b9d2c",
   "metadata": {},
   "source": [
    "## Datasetを指定\n",
    "\n",
    "DATA_SETSの配列は、自分の作成したデータ設定名に修正します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3db388d",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_SETS = [\"dataset/tokyo_1121_data_001\",\"dataset/tokyo_1121_data_002\",\"dataset/tokyo_1121_data_003\",\"dataset/tokyo_1121_data_004\",\"dataset/tokyo_1121_data_005\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2fcbd424",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import time\n",
    "from xy_dataset import XYDataset\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "def load_data(path=''):\n",
    "    global dataset\n",
    "    CATEGORIES = ['xy','speed']\n",
    "    TRANSFORMS = transforms.Compose([\n",
    "        transforms.ColorJitter(0.2, 0.2, 0.2, 0.2),\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    dataset = XYDataset(path, CATEGORIES, TRANSFORMS, random_hflip=True)\n",
    "    print(f'データを{len(dataset)} 件読み込みました')\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "577ffc19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "データを157 件読み込みました\n",
      "データを111 件読み込みました\n",
      "データを189 件読み込みました\n",
      "データを274 件読み込みました\n",
      "データを50 件読み込みました\n",
      "全データセットを結合しました。合計 781 件のデータがあります。\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import ConcatDataset\n",
    "\n",
    "all_datasets = []\n",
    "for dataset_path in DATA_SETS:\n",
    "    dataset = load_data(dataset_path)\n",
    "    all_datasets.append(dataset)\n",
    "\n",
    "# Concatenate all datasets\n",
    "full_dataset = ConcatDataset(all_datasets)\n",
    "print(f'全データセットを結合しました。合計 {len(full_dataset)} 件のデータがあります。')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "769b63cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "device = torch.device('cuda')\n",
    "\n",
    "def pretrained_model():\n",
    "    # ALEXNET\n",
    "    # model = torchvision.models.alexnet(pretrained=True)\n",
    "    # model.classifier[-1] = torch.nn.Linear(4096, output_dim)\n",
    "\n",
    "    # SQUEEZENET\n",
    "    # model = torchvision.models.squeezenet1_1(pretrained=True)\n",
    "    # model.classifier[1] = torch.nn.Conv2d(512, output_dim, kernel_size=1)\n",
    "    # model.num_classes = len(dataset.categories)\n",
    "\n",
    "    # RESNET 18\n",
    "    model = torchvision.models.resnet18(pretrained=True)\n",
    "    model.fc = torch.nn.Linear(512, output_dim)\n",
    "\n",
    "    # RESNET 34\n",
    "    # model = torchvision.models.resnet34(pretrained=True)\n",
    "    # model.fc = torch.nn.Linear(512, output_dim)\n",
    "\n",
    "    # DENSENET 121\n",
    "    # model = torchvision.models.densenet121(pretrained=True)\n",
    "    # model.classifier = torch.nn.Linear(model.classifier.in_features, output_dim)\n",
    "\n",
    "    return model\n",
    "\n",
    "def weights_model():\n",
    "    # ALEXNET\n",
    "    # model = torchvision.models.alexnet(weights=torchvision.models.AlexNet_Weights.DEFAULT)\n",
    "    # model.classifier[-1] = torch.nn.Linear(4096, output_dim)\n",
    "\n",
    "    # SQUEEZENET\n",
    "    # model = torchvision.models.squeezenet1_1(weights=torchvision.models.SqueezeNet1_1_Weights.DEFAULT)\n",
    "    # model.classifier[1] = torch.nn.Conv2d(512, output_dim, kernel_size=1)\n",
    "    # model.num_classes = len(dataset.categories)\n",
    "\n",
    "    # RESNET 18\n",
    "    model = torchvision.models.resnet18(weights=torchvision.models.ResNet18_Weights.DEFAULT)\n",
    "    model.fc = torch.nn.Linear(512, output_dim)\n",
    "\n",
    "    # RESNET 34\n",
    "    # model = torchvision.models.resnet34(weights=torchvision.models.ResNet34_Weights.DEFAULT)\n",
    "    # model.fc = torch.nn.Linear(512, output_dim)\n",
    "\n",
    "    # DENSENET 121\n",
    "    # model = torchvision.models.densenet121(weights=torchvision.models.DenseNet121_Weights.DEFAULT)\n",
    "    # model.classifier = torch.nn.Linear(model.classifier.in_features, output_dim)\n",
    "\n",
    "    return model\n",
    "\n",
    "def load_trained_mode():\n",
    "    global model\n",
    "    \n",
    "    version_str = torchvision.__version__\n",
    "    match = re.match(r'(\\d+)\\.(\\d+)\\.(\\d+)', version_str)\n",
    "    if match:\n",
    "        major, minor, _ = map(int, match.groups())\n",
    "        # 0.13以上の場合\n",
    "        if major > 0 or minor >= 13:\n",
    "            # RESNET 18\n",
    "            model = torchvision.models.resnet18(weights=None)  # pretrained=Falseの代わり\n",
    "            model.fc = torch.nn.Linear(model.fc.in_features, output_dim)\n",
    "        else:\n",
    "            model = torchvision.models.resnet18(pretrained=False)\n",
    "            model.fc = torch.nn.Linear(512, output_dim)\n",
    "    \n",
    "def load_pretrained_model():\n",
    "    global model\n",
    "    print('Pre-trainedモデルを読み込みます。')\n",
    "    # torchvisionのバージョン文字列を取得\n",
    "    version_str = torchvision.__version__\n",
    "\n",
    "    # 正規表現でメジャー、マイナー、パッチのバージョンを抜き出す\n",
    "    match = re.match(r'(\\d+)\\.(\\d+)\\.(\\d+)', version_str)\n",
    "    if match:\n",
    "        major, minor, _ = map(int, match.groups())\n",
    "        # 0.13以上の場合\n",
    "        if major > 0 or minor >= 13:\n",
    "            # pretrainedが非推奨となったため、最新の学習済みwightsを使う\n",
    "            # https://pytorch.org/blog/introducing-torchvision-new-multi-weight-support-api/\n",
    "            model = weights_model()\n",
    "        else:\n",
    "            # pretrainedを使う\n",
    "            model = pretrained_model()\n",
    "    else:\n",
    "        print(\"Unable to parse torchvision version\")\n",
    "\n",
    "def load_model(model_file):\n",
    "    global model, optimizer, output_dim\n",
    "    # 前提：datasetを読み込み済み\n",
    "    output_dim = 2 * len(dataset.categories)  # x, y coordinate for each category\n",
    "\n",
    "    # 学習済みの重みがあれば読み込みます\n",
    "    if os.path.exists(model_file):\n",
    "        print(f'重み情報{model_file}を読み込みます。')\n",
    "        load_trained_mode()\n",
    "        model = model.to(device)\n",
    "        model.load_state_dict(torch.load(model_file))\n",
    "    else:\n",
    "        # PreTraingのモデルを読み込みます\n",
    "        load_pretrained_model()\n",
    "        model = model.to(device)\n",
    "    \n",
    "    model = model.eval()\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "def save_model(model_file):\n",
    "    # 学習済みの重みを.pthファイルに保存します。(モデル構造は含みません)\n",
    "    torch.save(model.state_dict(), model_file)\n",
    "    print(\"学習結果を\" + model_file + \"に保存しました。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e14cacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from IPython.display import clear_output\n",
    "import torch.utils.data as data\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "038ac6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初期の最良の損失値を無限大として設定\n",
    "best_test_loss = float('inf')\n",
    "best_train_loss = float('inf')\n",
    "# 学習と評価の損失の履歴\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "# エポックの履歴\n",
    "epochs = []\n",
    "\n",
    "def filter_none(data):\n",
    "    return [(images, category_idx, xy) for images, category_idx, xy in data if images is not None and xy is not None and category_idx is not None]\n",
    "\n",
    "def train_eval(is_training=True, batch_size=8, epoch=20, stop_count=10):\n",
    "    global model, full_dataset, optimizer, best_test_loss, best_train_loss\n",
    "\n",
    "    # 破損データ等を対象外にする\n",
    "    valid_data = []\n",
    "    for i in range(len(full_dataset)):\n",
    "        try:\n",
    "            _ = full_dataset[i]\n",
    "            valid_data.append(full_dataset[i])\n",
    "        except AttributeError as e:\n",
    "            print(f\"無効なデータが検出されました（インデックス：{i}）: {e}\")\n",
    "\n",
    "    full_dataset = valid_data\n",
    "\n",
    "    # FilterでNoneデータを削除\n",
    "    full_dataset = filter_none(full_dataset)\n",
    "\n",
    "    # データ数を計算\n",
    "    total_size = len(full_dataset)\n",
    "\n",
    "    # テストデータの割合\n",
    "    split_size = total_size * 10 // 100  # １0%をテストデータとして使用\n",
    "    \n",
    "    # テストデータと学習データに切り分け\n",
    "    indices = list(range(total_size))\n",
    "    train_indices, test_indices = indices[split_size:], indices[:split_size]\n",
    "    train_dataset = data.Subset(full_dataset, train_indices)\n",
    "    test_dataset = data.Subset(full_dataset, test_indices)\n",
    "\n",
    "    # データセットを作成\n",
    "    train_loader = data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = data.DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    model = model.train()\n",
    "    non_improving_epochs = 0\n",
    "    epoch_count = 0\n",
    "\n",
    "    try:\n",
    "        while epoch > 0:\n",
    "            sum_train_loss = 0.0\n",
    "\n",
    "            # グラフを描画\n",
    "            data_size = len(train_loader) * batch_size\n",
    "            clear_output(wait=True)\n",
    "            plt.plot(epochs, train_losses, label='Train Loss')\n",
    "            plt.plot(epochs, test_losses, label='Test Loss')\n",
    "            plt.title(f\"Train Loss ({total_size - split_size} datas) vs Test Loss({split_size} datas)\")\n",
    "            plt.xlabel('Epochs')\n",
    "            plt.ylabel('Loss')\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            plt.show()\n",
    "\n",
    "            # 時刻計測\n",
    "            start_time = time.time()\n",
    "\n",
    "            # 学習の進行状況を表示するプログレスバー\n",
    "            progress_bar = tqdm(enumerate(train_loader), total=len(train_loader), desc=f\"Epoch {epoch_count + 1}\")\n",
    "\n",
    "            for i, (images, category_idx, xy) in progress_bar:\n",
    "                if images is None or xy is None:\n",
    "                    print(\"Warning: None type data found at index\", i)\n",
    "                    continue\n",
    "                \n",
    "                # GPUメモリに転送\n",
    "                images = images.to(device)\n",
    "                xy = xy.to(device)\n",
    "                \n",
    "                # 前のepochの勾配をクリア\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                outputs = model(images)\n",
    "                loss = 0.0\n",
    "                for batch_idx, cat_idx in enumerate(list(category_idx.flatten())):\n",
    "                    loss += torch.mean((outputs[batch_idx][2 * cat_idx:2 * cat_idx+2] - xy[batch_idx])**2)\n",
    "                loss /= len(category_idx)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                sum_train_loss += float(loss)\n",
    "\n",
    "                # 進行状況バーに損失値を表示\n",
    "                average_loss = sum_train_loss / (i + 1)\n",
    "                progress_bar.set_description(f\"Epoch {epoch_count + 1} Loss: {average_loss:.5f}\")\n",
    "\n",
    "            # Train損出を計算しグラフ用の配列に格納\n",
    "            train_loss = sum_train_loss / len(train_loader)\n",
    "            train_losses.append(train_loss)\n",
    "\n",
    "            # テストデータを使っての評価\n",
    "            model = model.eval()\n",
    "            sum_test_loss = 0.0\n",
    "            with torch.no_grad():\n",
    "                for images, category_idx, xy in test_loader:\n",
    "                    if images is None or xy is None:\n",
    "                        print(\"Error: None type data found at index\", i)\n",
    "                        continue\n",
    "\n",
    "                    images = images.to(device)\n",
    "                    xy = xy.to(device)\n",
    "                    outputs = model(images)\n",
    "                    loss = 0.0\n",
    "                    for batch_idx, cat_idx in enumerate(list(category_idx.flatten())):\n",
    "                        loss += torch.mean((outputs[batch_idx][2 * cat_idx:2 * cat_idx+2] - xy[batch_idx])**2)\n",
    "                    loss /= len(category_idx)\n",
    "                    sum_test_loss += float(loss)\n",
    "\n",
    "            # Test損出を計算しグラフ用の配列に格納\n",
    "            test_loss = sum_test_loss / len(test_loader)\n",
    "            test_losses.append(test_loss)\n",
    "              \n",
    "            # Testデータ数が100を超えるまではtrain_lossで評価\n",
    "            best_model = False\n",
    "            if split_size > 100:\n",
    "                if test_loss < best_test_loss:   \n",
    "                    best_test_loss = test_loss   \n",
    "                    non_improving_epochs = 0\n",
    "\n",
    "                    # Bestモデルを保存\n",
    "                    save_model(\"./model/train_best_model.pth\")\n",
    "                    print(\"Saved best model with test loss:\", best_test_loss)\n",
    "                    best_model = True\n",
    "                else:\n",
    "                    non_improving_epochs += 1\n",
    "            else:\n",
    "                if train_loss < best_train_loss:   \n",
    "                    best_train_loss = train_loss  \n",
    "                    non_improving_epochs = 0\n",
    "\n",
    "                    # Bestモデルを保存\n",
    "                    save_model(\"./model/train_best_model.pth\")\n",
    "                    print(\"Saved best model with test loss:\", best_train_loss)\n",
    "                    best_model = True\n",
    "                else:\n",
    "                    non_improving_epochs += 1\n",
    "\n",
    "            # Epochをマイナス1, グラフ用には+1\n",
    "            epoch -= 1\n",
    "            epoch_count += 1\n",
    "            epochs.append(epoch_count)\n",
    "            \n",
    "            # evalからtrainに戻す\n",
    "            model = model.train()\n",
    "\n",
    "            # log.txtに学習状況を追記\n",
    "            with open(\"./log.txt\", \"a\") as file:\n",
    "                end_time = time.time()  \n",
    "                epoch_duration = end_time - start_time  \n",
    "                total_time = (epoch_count + 1) * epoch_duration \n",
    "\n",
    "                file.write(f\"Epoch {epoch_count}: Train Loss: {loss:.5f}, Test Loss: {test_loss:.5f}, Best Model: {best_model}, Time: {epoch_duration/60:.4f} 分, Total time: {total_time/60:.4f} 分\\n\")\n",
    "\n",
    "            if non_improving_epochs >= stop_count:\n",
    "                print(\"Loss hasn't improved for {} consecutive epochs. Stopping training.\".format(MAX_NON_IMPROVING_EPOCHS))\n",
    "                break\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1f132b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-trainedモデルを読み込みます。\n"
     ]
    }
   ],
   "source": [
    "MAX_NON_IMPROVING_EPOCHS = 30\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 8\n",
    "# 初期の最良の損失値を無限大として設定\n",
    "best_loss = float('inf')\n",
    "# 学習と評価の損失の履歴\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "# エポックの履歴\n",
    "epochs = []\n",
    "\n",
    "load_model(\"\")\n",
    "# best_model.pthを追加で学習する場合\n",
    "#load_model(\"best_model.pth\")\n",
    "train_eval(batch_size=BATCH_SIZE, epoch=EPOCHS, stop_count=MAX_NON_IMPROVING_EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b543b816-3a02-44ab-99a3-7cf457834189",
   "metadata": {},
   "source": [
    "## 動画の作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44618e1e-29ef-4a8e-b807-ce7caca72b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets\n",
    "from ipywidgets import Button, Layout, Textarea, HBox, VBox, Label\n",
    "import os\n",
    "import glob\n",
    "\n",
    "l = Layout(flex='0 1 auto', height='100px', min_height='100px', width='auto')\n",
    "process_widget = ipywidgets.Textarea(description='ログ', value='', layout=l)\n",
    "\n",
    "process_no = 0\n",
    "def write_log(msg):\n",
    "    global process_widget, process_no\n",
    "    process_no = process_no + 1\n",
    "    process_widget.value = str(process_no) + \": \" + msg + \"\\n\" + process_widget.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec09a7c-89ff-49de-8c4d-83fbfc3ff8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOAD_TASK = ['camera']\n",
    "IMG_WIDTH = 224\n",
    "IMG_HEIGHT = 224\n",
    "current_path = os.getcwd()\n",
    "SKIP = [1,2,3,4,5]\n",
    "\n",
    "load_datasets_widget = ipywidgets.Dropdown(options=[], description='dataset')\n",
    "load_task_widget = ipywidgets.Dropdown(options=LOAD_TASK, description='task')\n",
    "movie_button = ipywidgets.Button(description='動画の作成')\n",
    "movie_name_widget = ipywidgets.Text(description='動画名',value=\"run_video_train\")\n",
    "movie_skip_dropdown = ipywidgets.Dropdown(options=SKIP, description='skip(枚)', index=1)\n",
    "\n",
    "def change_load_task(change):\n",
    "    global current_path\n",
    "    try:\n",
    "        path = os.path.join(current_path,load_task_widget.value)\n",
    "        files = os.listdir(path)\n",
    "        dirs = [f for f in files if os.path.isdir(os.path.join(path, f))]\n",
    "        dirs = [f for f in files if f != \".ipynb_checkpoints\"]\n",
    "        dirs = sorted(dirs)\n",
    "        load_datasets_widget.options = dirs\n",
    "    except:\n",
    "        write_log(path + \"が存在していません。\")\n",
    "        load_datasets_widget.options = []\n",
    "load_task_widget.observe(change_load_task)\n",
    "change_load_task(LOAD_TASK[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306d28e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import glob\n",
    "from utils import preprocess\n",
    "import re\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "\n",
    "load_model(\"./model/train_best_model.pth\")\n",
    "\n",
    "def extract_numbers(filename):\n",
    "    matches = re.findall(r'(\\d+)', filename)\n",
    "    if matches and len(matches) >= 3: \n",
    "        return int(matches[-1])  \n",
    "    else:\n",
    "        return float('inf')\n",
    "\n",
    "def get_file_names(path):\n",
    "    file_names = os.listdir(path)\n",
    "    file_names = [os.path.join(path, file_name) for file_name in file_names]\n",
    "    image_names = []\n",
    "\n",
    "    image_names = sorted(file_names, key=lambda f: extract_numbers(os.path.basename(f)))\n",
    "    image_names = [f for f in image_names if os.path.splitext(f)[1].lower() == \".jpg\"]\n",
    "    \n",
    "    return image_names\n",
    "\n",
    "def make_movie(change):\n",
    "    global model,current_path\n",
    "    \n",
    "    if not movie_name_widget.value.strip():\n",
    "        write_log(\"ファイル名を指定してください。\")\n",
    "        return \n",
    "    write_log(\"動画を作成します。\")\n",
    "    path = os.path.join(current_path, \"video/\")\n",
    "    if not os.path.exists(path):\n",
    "        subprocess.call(['mkdir', '-p', path])\n",
    "    output = path + movie_name_widget.value + \".mp4\"\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    fps = int(30 / movie_skip_dropdown.value)\n",
    "    outfh = cv2.VideoWriter(output, fourcc, fps, (224, 224))\n",
    "    file_list = sorted(\n",
    "        glob.glob(load_task_widget.value + '/' + load_datasets_widget.value + '/xy/*.jpg'),\n",
    "        key=os.path.getmtime\n",
    "    )\n",
    "    \n",
    "    xy_path = os.path.join(current_path, load_task_widget.value, load_datasets_widget.value, \"xy\")     \n",
    "    file_list = os.listdir(xy_path)\n",
    "    file_list = [os.path.join(xy_path, file_name) for file_name in file_list if file_name.endswith('.jpg')]    \n",
    "    file_list = sorted(file_list, key=lambda f: extract_numbers(os.path.basename(f)))\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        res_num = len(file_list)\n",
    "        \n",
    "        count = 0\n",
    "        skip_movie = movie_skip_dropdown.value\n",
    "        terminal_time = 1/(30/skip_movie)\n",
    "        current_time = 0\n",
    "        process_time = 0\n",
    "        total_process_time = 0\n",
    "        for i, file_name in enumerate(file_list):\n",
    "            \n",
    "            if i % skip_movie == 0:\n",
    "                current_time += terminal_time\n",
    "                img = cv2.imread(file_name)\n",
    "                \n",
    "                process_time = time.time()\n",
    "                preprocessed = preprocess(img)\n",
    "                output = model(preprocessed).detach().cpu().numpy().flatten()\n",
    "                result_x = float(output[0])\n",
    "                result_y = float(output[1])\n",
    "                result_x = int(IMG_WIDTH * (result_x / 2.0 + 0.5))\n",
    "                result_y = int(IMG_HEIGHT * (result_y / 2.0 + 0.5))    \n",
    "                img = cv2.circle(img, (int(result_x), int(result_y)), 8, (255, 0, 0), 3)\n",
    "\n",
    "                # Speed\n",
    "                result_speed = output[3]\n",
    "                result_speed = int(IMG_WIDTH * (result_speed / 2.0 + 0.5))\n",
    "                if result_speed > 224:\n",
    "                    result_speed = 244\n",
    "                elif result_speed < 0:\n",
    "                    result_speed = 0\n",
    "                img = cv2.line(img,(218,0),(218,224),(0,0,0),5)\n",
    "                img = cv2.line(img,(219,224-result_speed),(219,224),(0,140,255),3)\n",
    "                img = cv2.putText(img,\"speed:\"+str(result_speed),(160,215),cv2.FONT_HERSHEY_SIMPLEX,0.3,(255,255,255))\n",
    "                total_process_time += time.time() - process_time \n",
    "                \n",
    "                if i % (skip_movie*10) == 0:\n",
    "                    write_log(f\"{current_time:.1f}秒まで完了, 推論処理平均: {total_process_time/10*1000:.1f}ms, {int(i/skip_movie)}枚目/{int(res_num/skip_movie)}枚中を処理中\")\n",
    "                    total_process_time = 0\n",
    "                outfh.write(img)\n",
    "                del img\n",
    "    finally:\n",
    "        # エラーが発生しても確実にリソースを解放する\n",
    "        outfh.release()\n",
    "        write_log(\"動画の出力が完了しました。\")\n",
    "\n",
    "movie_button.on_click(make_movie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c483ac-6eaa-4227-add7-5a838c01ce26",
   "metadata": {},
   "outputs": [],
   "source": [
    "separator = ipywidgets.HTML('<hr style=\"border-color:gray;margin:10px 0\"/>')\n",
    "title1 = ipywidgets.HTML('<b>【走行動画の作成】</b> 動画ファイル名を指定してください。')\n",
    "\n",
    "convert_widget = ipywidgets.VBox([\n",
    "    separator,\n",
    "    title1,\n",
    "    ipywidgets.HBox([load_datasets_widget,load_task_widget]),\n",
    "    ipywidgets.HBox([movie_name_widget,movie_skip_dropdown,movie_button]),\n",
    "    process_widget,\n",
    "])\n",
    "display(convert_widget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60d369c-acca-41a9-a158-0ad072e463a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08004af8-5733-4db2-9911-1dad02c012a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
