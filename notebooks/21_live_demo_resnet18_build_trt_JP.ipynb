{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collision Avoidance - ResNet18をTensorRTに変換\n",
    "\n",
    "学習したPytorchモデルをTensorRTで最適化します。  \n",
    "``02_train_model_resnet18_JP.ipynb``ノートブックの指示に従って、すでに``best_model_resnet18.pth``を作成していることを想定します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習済みモデルの読み込み\n",
    "最初にtorchvisionで提供されている未学習のResNet18モデルを読み込みます。(自前学習した値でモデルを初期化するため、ImageNetで学習済みのモデルである必要がありません。)  \n",
    "次に、ResNet18モデル構造の全結合層(fully connected layer)を入れ替えて、JetBotの衝突回避モデルで欲しい出力「free」と「blocked」の2種類を得られるモデル構造にします。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "# 利用するライブラリを読み込みます。\n",
    "########################################\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "########################################\n",
    "# PyTorchで提供されている未学習のResNet18モデルを読込みます。\n",
    "########################################\n",
    "model = torchvision.models.resnet18(pretrained=False)\n",
    "\n",
    "########################################\n",
    "# モデルの出力層をJetBotの道路走行モデル用に置き換えます。\n",
    "########################################\n",
    "model.fc = torch.nn.Linear(512, 4)\n",
    "\n",
    "########################################\n",
    "# GPU処理が可能な部分をGPUで処理するように設定します。\n",
    "# model.eval()は推論実行前に必ず必要になります。\n",
    "# これはDropoutレイヤーとバッチ正規化レイヤーを学習モードから評価モードに変更します。\n",
    "# これらは学習時に精度を高めるためにランダムで適用される機能であり、\n",
    "# 推論時には精度を上げるためにmodel.eval()を実行してこれらの機能を無効にします。\n",
    "# また、float16型に変更します。\n",
    "########################################\n",
    "model = model.cuda().eval().half()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次に、学習済みモデル``best_model_resnet18.pth``から値を読み込み、ResNet18モデルにウェイトを設定します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "########################################\n",
    "# 未学習のモデルに学習結果の重みづけを読込みます。\n",
    "########################################\n",
    "model.load_state_dict(torch.load('./detection.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorRTはGPUの利用が必須であり、最初からGPU向けに実装されています。  \n",
    "そのため、モデルに対するデバイス指定は不要です。  \n",
    "しかしデータに対しては同じデバイス上に存在する必要があるため、GPUへの転送が必要になります。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "# このデバイス定義は利用されていません。\n",
    "########################################\n",
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorRTモデルに変換\n",
    "\n",
    "TorchからTensorRTに変換します。  \n",
    "TensorRTでの推論を高速化するために、torch2trtを使用してモデルを変換および最適化します。  \n",
    "詳細については、[torch2trt](https://github.com/NVIDIA-AI-IOT/torch2trt)のreadmeを参照してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "# 利用するライブラリを読み込みます。\n",
    "########################################\n",
    "from torch2trt import torch2trt\n",
    "\n",
    "########################################\n",
    "# TensorRT化する際に、サンプルの入力データを渡す必要があります。\n",
    "# サンプルの入力データを作成します。\n",
    "# サンプルデータはGPUデバイスにfloat16型で作成します。\n",
    "########################################\n",
    "data = torch.zeros((1, 3, 224, 224)).cuda().half()\n",
    "\n",
    "########################################\n",
    "# TensorRTモデルを作成します。\n",
    "########################################\n",
    "model_trt = torch2trt(model, [data], fp16_mode=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorRTモデルをファイルに保存します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "# TensorRTモデルをファイルに保存します。\n",
    "########################################\n",
    "torch.save(model_trt.state_dict(), 'detection_trt.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 次\n",
    "JetBot本体で学習した場合は、このノートブックを閉じてからJupyter左側にある「Running Terminals and Kernels」を選択して「03_live_demo_resnet18_build_trt_JP.ipynb」の横にある「SHUT DOWN」をクリックしてJupyter Kernelをシャットダウンしてから[04_live_demo_resnet18_trt_JP.ipynb](04_live_demo_resnet18_trt_JP.ipynb)に進んでください。  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
